---
title: "NLP Project: Beyond Words: Enhancing Reasoning in Entity Tracking"
excerpt: "The paper evaluates the impact of fine-tuning reasoning models on entity tracking, using a T5-base model and focusing on mathematical and computational reasoning tasks. It compares performance across various datasets: general knowledge, coding, and math. Results show that models trained on coding datasets excel in entity tracking, while those trained on math face challenges with unfamiliar symbols.<br/><img src='/images/NLP.png'>"
collection: portfolio
---

This paper explores the impact of fine-tuning models equipped with reasoning capabilities on entity tracking. Leveraging a T5-base model, we evaluate the effects of fine-tuning via two distinct avenues: mathematical reasoning using mathematical question-answer pairs and computational reasoning with coding-related question-answer pairs. The study investigates the models’ performances across individual datasets—general knowledge, code,
and math—as well as their combinations. Results demonstrate that models trained on code-only datasets exhibit superior entity tracking capabilities compared to general knowledge-based models, while those trained on mathematical reasoning exhibit challenges due to out-of-vocabulary symbols 

[Download paper here](/files/6_8610_Project_Final_Paper.pdf)